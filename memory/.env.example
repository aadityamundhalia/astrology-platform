# Ollama Configuration
# Base URL for Ollama API (default localhost)
OLLAMA_BASE_URL=http://localhost:11434
# Main LLM model for chat and reformatting
OLLAMA_MODEL=llama3.2
# Embedding model for vectorization
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# Base URL for embedding model (usually same as above)
OLLAMA_EMBEDDING_BASE_URL=http://localhost:11434

# Qdrant Configuration
# Host for Qdrant vector database
QDRANT_HOST=localhost
# Port for Qdrant (default 6333)
QDRANT_PORT=6333
# Collection name for storing vectors
QDRANT_COLLECTION=mem0_collection

# Feature Flags
# Enable LLM-based query reformatting for better search results
USE_LLM_REFORMAT=false