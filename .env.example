# ====================================
# ASTROLOGY PLATFORM - ENVIRONMENT VARIABLES TEMPLATE
# ====================================
# Copy this file to .env and fill in your actual values

# -------------------- Infrastructure Ports --------------------
POSTGRES_PORT=5433
REDIS_PORT=6380
RABBITMQ_PORT=5673
RABBITMQ_MANAGEMENT_PORT=15673
QDRANT_HTTP_PORT=6334
QDRANT_GRPC_PORT=6335

# -------------------- Application Ports --------------------
BOT_PORT=8282
MEMORY_SERVICE_PORT=8085
ASTROLOGY_MCP_PORT=8585

# -------------------- PostgreSQL --------------------
POSTGRES_DB=astrology
POSTGRES_USER=your_db_user
POSTGRES_PASSWORD=your_secure_password

# -------------------- Redis --------------------
REDIS_DB=0
REDIS_PASSWORD=your_redis_password
REDIS_CHAT_HISTORY_LIMIT=15

# -------------------- RabbitMQ --------------------
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest
RABBITMQ_VHOST=/
RABBITMQ_QUEUE=astrology_requests
RABBITMQ_WORKERS=1

# -------------------- Qdrant --------------------
QDRANT_COLLECTION=mem0_collection

# -------------------- Ollama (External) --------------------
# Point to your existing Ollama instance
OLLAMA_HOST=http://192.168.0.200:11435
OLLAMA_MODEL=gpt-oss:latest
OLLAMA_EMBEDDING_BASE_URL=http://192.168.0.200:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# -------------------- Telegram Bot --------------------
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# -------------------- Chat Encryption --------------------
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
CHAT_ENCRYPTION_KEY=your_encryption_key_here

# -------------------- LLM Settings --------------------
ENABLE_THINKING=true
THINKING_MAX_TOKENS=500
THINKING_TEMPERATURE=0.75

# -------------------- Memory Service --------------------
USE_LLM_REFORMAT=false

# -------------------- User Management --------------------
MAX_STRIKES=3
ENABLE_PROFANITY_FILTER=true

# -------------------- Application Settings --------------------
LOG_LEVEL=INFO